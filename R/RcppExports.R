# Generated by using Rcpp::compileAttributes() -> do not edit by hand
# Generator token: 10BE3573-1514-4C36-9D1C-5A225CD40393

#' Computes SVD decomposition
#'
#' This is direct implementation of the randomized SVD algorithm for sparse matrices:
#' Xu Feng, Yuyang Xie, and Yaohang Li, "Fast Randomzied SVD for Sparse Data," in Proc. the 10th Asian Conference on Machine Learning (ACML), Beijing, China, Nov. 2018.
#' 
#' @param A Input matrix (either a "matrix" or "sparseMatrix")
#' @param dim Dimension of SVD decomposition
#' @param iters Number of iterations (default=5)
#' @param seed Random seed (default=0)
#' 
#' @return A named list with U, sigma, and V components
#' 
#' @examples
#' A = randn(100, 20)
#' SVD.out = FengSVD(A, dim = 2)
#' U = SVD.out$U
FengSVD <- function(A, dim, iters = 5L, seed = 0L) {
    .Call(`_ACTIONet_FengSVD`, A, dim, iters, seed)
}

#' Computes SVD decomposition
#'
#' This is direct implementation of the randomized SVD algorithm:
#' XFrom: N Halko, P. G Martinsson, and J. A Tropp. Finding structure with randomness: Probabilistic algorithms for constructing approximate matrix decompositions. Siam Review, 53(2):217-288, 2011.
#' 
#' @param A Input matrix (either a "matrix" or "sparseMatrix")
#' @param dim Dimension of SVD decomposition
#' @param iters Number of iterations (default=5)
#' @param seed Random seed (default=0)
#' 
#' @return A named list with U, sigma, and V components
#' 
#' @examples
#' A = randn(100, 20)
#' SVD.out = HalkoSVD(A, dim = 2)
#' U = SVD.out$U
HalkoSVD <- function(A, dim, iters = 5L, seed = 0L) {
    .Call(`_ACTIONet_HalkoSVD`, A, dim, iters, seed)
}

#' Computes reduced kernel matrix for a given (single-cell) profile
#'
#' @param S Input matrix (either a "matrix" or "sparseMatrix")
#' @param reduced_dim Dimension of the reduced kernel matrix (default=50)
#' @param iters Number of SVD iterations (default=5)
#' @param seed Random seed (default=0)
#' @param reduction_algorithm Kernel reduction algorithm. Currently only ACTION method (1) is implemented (default=1)
#' @param SVD_algorithm SVD algorithm to use. Currently supported methods are Halko (1) and Feng (2) (default=1)
#' 
#' @return A named list with S_r, V, lambda, and exp_var. \itemize{
#' \item S_r: reduced kernel matrix of size reduced_dim x #samples.
#' \item V: Associated left singular-vectors (useful for reconstructing discriminative scores for features, such as genes).
#' \item lambda, exp_var: Summary statistics of the sigular-values.
#' }
#' 
#' @examples
#' S = logcounts(sce)
#' reduction.out = reduce(S, reduced_dim = 50)
#' S_r = reduction.out$S_r
reduce_kernel <- function(S, reduced_dim = 50L, iter = 5L, seed = 0L, reduction_algorithm = 1L, SVD_algorithm = 1L) {
    .Call(`_ACTIONet_reduce_kernel`, S, reduced_dim, iter, seed, reduction_algorithm, SVD_algorithm)
}

#' Solves min_{X} (|| AX - B ||) s.t. simplex constraint
#'
#' @param A Input matrix
#' @param B Input matrix
#' 
#' @return X Solution
#' 
#' @examples
#' C = ACTION.out$C[[10]]
#' A = S_r %*% C
#' B = S_r
#' H = run_simplex_regression(A, B)
run_simplex_regression <- function(A, B) {
    .Call(`_ACTIONet_run_simplex_regression`, A, B)
}

#' Runs Successive Projection Algorithm (SPA) to solve separable NMF
#'
#' @param A Input matrix
#' @param k Number of columns to select
#' 
#' @return A named list with entries 'selected_columns' and 'norms'
#' @examples
#' H = run_SPA(S_r, 10)
run_SPA <- function(A, k) {
    .Call(`_ACTIONet_run_SPA`, A, k)
}

#' Runs multi-level ACTION decomposition method
#'
#' @param S_r Reduced kernel matrix
#' @param k_min Minimum number of archetypes to consider (default=2)
#' @param k_max Maximum number of archetypes to consider, or "depth" of decomposition (default=30)
#' @param thread_no Number of parallel threads (default=4)
#' 
#' @return A named list with entries 'C' and 'H', each a list for different values of k
#' @examples
#' ACTION.out = run_ACTION(S_r, k_max = 10)
#' H8 = ACTION.out$H[[8]]
#' cell.assignments = apply(H8, 2, which.max)
run_ACTION <- function(S_r, k_min = 2L, k_max = 30L, thread_no = 4L, max_it = 50L, min_delta = 0.01) {
    .Call(`_ACTIONet_run_ACTION`, S_r, k_min, k_max, thread_no, max_it, min_delta)
}

#' Runs multi-level ACTION decomposition method
#'
#' @param S_r Reduced kernel matrix
#' @param w Weight vector for each observation
#' @param k_min Minimum number of archetypes to consider (default=2)
#' @param k_max Maximum number of archetypes to consider, or "depth" of decomposition (default=30)
#' @param thread_no Number of parallel threads (default=4)
#' 
#' @return A named list with entries 'C' and 'H', each a list for different values of k
#' @examples
#' ACTION.out = run_ACTION(S_r, k_max = 10)
#' H8 = ACTION.out$H[[8]]
#' cell.assignments = apply(H8, 2, which.max)
run_weighted_ACTION <- function(S_r, w, k_min = 2L, k_max = 30L, thread_no = 4L, max_it = 50L, min_delta = 0.01) {
    .Call(`_ACTIONet_run_weighted_ACTION`, S_r, w, k_min, k_max, thread_no, max_it, min_delta)
}

#' Filters multi-level archetypes and concatenate filtered archetypes.
#' (Pre-ACTIONet archetype processing)
#'
#' @param C_trace,H_trace Output of ACTION
#' @param min_specificity_z_threshold Defines the stringency of pruning nonspecific archetypes. 
#' The larger the value, the more archetypes will be filtered out (default=-1)
#' 
#' @return A named list: \itemize{
#' \item selected_archs: List of final archetypes that passed the filtering/pruning step.
#' \item C_stacked,H_stacked: Horizontal/Vertical concatenation of filtered C and H matrices, respectively.
#' }
#' @examples
#' S = logcounts(sce)
#' reduction.out = reduce(S, reduced_dim = 50)
#' S_r = reduction.out$S_r
#' ACTION.out = run_ACTION(S_r, k_max = 10)
#' reconstruction.out = reconstruct_archetypes(S, ACTION.out$C, ACTION.out$H)
prune_archetypes <- function(C_trace, H_trace, min_specificity_z_threshold = -1) {
    .Call(`_ACTIONet_prune_archetypes`, C_trace, H_trace, min_specificity_z_threshold)
}

#' Identifies and aggregates redundant archetypes into equivalent classes
#' (Post-ACTIONet archetype processing)
#'
#' @param G Adjacency matrix of the ACTIONet graph
#' @param S_r Reduced kernel profile
#' @param C_stacked,H_stacked Output of reconstruct_archetypes()
#' 
#' @return A named list: \itemize{
#' \item archetype_groups: Equivalent classes of archetypes (non-redundant)
#' \item C_unified,H_unified: C and H matrices of unified archetypes
#' \item sample_assignments: Assignment of samples/cells to unified archetypes
#' }
#' @examples
#' prune.out = prune_archetypes(ACTION.out$C, ACTION.out$H)
#'	G = build_ACTIONet(prune.out$H_stacked)
#' unification.out = unify_archetypes(G, S_r, prune.out$C_stacked, prune.out$H_stacked)
#' cell.clusters = unification.out$sample_assignments
unify_archetypes <- function(G, S_r, C_stacked, H_stacked, minPoints = 5L, minClusterSize = 5L, outlier_threshold = 0.0) {
    .Call(`_ACTIONet_unify_archetypes`, G, S_r, C_stacked, H_stacked, minPoints, minClusterSize, outlier_threshold)
}

#' Builds an interaction network from the multi-level archetypal decompositions
#'
#' @param H_stacked Output of the prune_archetypes() function.
#' @param density Overall density of constructed graph. The higher the density, the more edges are retained (default = 1.0).
#' @param thread_no Number of parallel threads (default = 4).
#' @param mutual_edges_only Symmetrization strategy for nearest-neighbor edges. 
#' If it is true, only mutual-nearest-neighbors are returned (default=TRUE).
#' 
#' @return G Adjacency matrix of the ACTIONet graph.
#' 
#' @examples
#' prune.out = prune_archetypes(ACTION.out$C, ACTION.out$H)
#'	G = build_ACTIONet(prune.out$H_stacked)
build_ACTIONet <- function(H_stacked, density = 1.0, thread_no = 8L, mutual_edges_only = TRUE) {
    .Call(`_ACTIONet_build_ACTIONet`, H_stacked, density, thread_no, mutual_edges_only)
}

#' Performs stochastic force-directed layout on the input graph (ACTIONet)
#'
#' @param G Adjacency matrix of the ACTIONet graph
#' @param S_r Reduced kernel matrix (is used for reproducible initialization).
#' @param compactness_level A value between 0-100, indicating the compactness of ACTIONet layout (default=50)
#' @param n_epochs Number of epochs for SGD algorithm (default=100).
#' @param thread_no Number of threads.
#' 
#' @return A named list \itemize{
#' \item coordinates 2D coordinates of vertices.
#' \item coordinates_3D 3D coordinates of vertices.
#' \item colors De novo color of nodes inferred from their 3D embedding.
#' }
#' 
#' @examples
#'	G = build_ACTIONet(prune.out$H_stacked)
#'	vis.out = layout_ACTIONet(G, S_r)
layout_ACTIONet <- function(G, S_r, compactness_level = 50L, n_epochs = 500L, thread_no = 4L) {
    .Call(`_ACTIONet_layout_ACTIONet`, G, S_r, compactness_level, n_epochs, thread_no)
}

#' Encrypts a set of given input ids
#'
#' @param ids List of input string ids
#' @param pass Pass phrase to use for encryption
#' 
#' @return A string array of encoded ids
#' 
#' @examples
#'	encoded.ids = encode_ids(colnames(sce))
encode_ids <- function(ids, pass) {
    .Call(`_ACTIONet_encode_ids`, ids, pass)
}

#' Decrypts a set of given encrypted ids
#'
#' @param encoded_ids List of encrypted string ids
#' @param pass Pass phrase to use for decryption
#' 
#' @return A string array of decrypted ids
#' 
#' @examples
#'	ids = decode_ids(encoded.ids)
decode_ids <- function(encoded_ids, pass) {
    .Call(`_ACTIONet_decode_ids`, encoded_ids, pass)
}

#' Computes pseudobulk profiles
#'
#' @param S Input matrix
#' @param sample_assignments Any sample clustering/annotation (it has to be in {1, ..., max_class_num})
#' 
#' @return S matrix aggregated within each class of sample_assignments
#' 
#' @examples
#' prune.out = prune_archetypes(ACTION.out$C, ACTION.out$H)
#'	G = build_ACTIONet(prune.out$H_stacked)
#' unification.out = unify_archetypes(G, S_r, prune.out$C_stacked, prune.out$H_stacked)
#' cell.clusters = unification.out$sample_assignments
#'	pbs = compute_pseudo_bulk(S, cell.clusters)
compute_pseudo_bulk <- function(S, sample_assignments) {
    .Call(`_ACTIONet_compute_pseudo_bulk`, S, sample_assignments)
}

#' Computes pseudobulk profiles (groups[k1] x individuals[k2])
#'
#' @param S Input matrix
#' @param sample_assignments Any primary grouping - typically based on cell type/state (it has to be in {1, ..., k1})
#' @param individuals Any Secondary grouping - typically corresponds to individuals (it has to be in {1, ..., k2})
#' 
#' @return A list of pseudobulk profile, where each entry is matrix corresponding to one cell type/state
#' 
#' @examples
#' prune.out = prune_archetypes(ACTION.out$C, ACTION.out$H)
#'	G = build_ACTIONet(prune.out$H_stacked)
#' unification.out = unify_archetypes(G, S_r, prune.out$C_stacked, prune.out$H_stacked)
#' cell.clusters = unification.out$sample_assignments
#'	pbs.list = compute_pseudo_bulk(S, cell.clusters, sce$individuals)
compute_pseudo_bulk_per_ind <- function(S, sample_assignments, individuals) {
    .Call(`_ACTIONet_compute_pseudo_bulk_per_ind`, S, sample_assignments, individuals)
}

#' Renormalized input matrix to minimize differences in means
#'
#' @param S Input matrix
#' @param sample_assignments Any primary grouping - typically based on cell type/state (it has to be in {1, ..., k1})
#' 
#' @return A list with the first entry being the renormalized input matrix
#' 
#' @examples
#' prune.out = prune_archetypes(ACTION.out$C, ACTION.out$H)
#'	G = build_ACTIONet(prune.out$H_stacked)
#' unification.out = unify_archetypes(G, S_r, prune.out$C_stacked, prune.out$H_stacked)
#' cell.clusters = unification.out$sample_assignments
#'	S.norm = renormalize_input_matrix(S, cell.clusters)
renormalize_input_matrix <- function(S, sample_assignments) {
    .Call(`_ACTIONet_renormalize_input_matrix`, S, sample_assignments)
}

#' Compute feature specificity (from archetype footprints)
#'
#' @param S Input matrix
#' @param H A soft membership matrix - Typically H_unified from the unify_archetypes() function.
#' 
#' @return A list with the over/under-logPvals
#' 
#' @examples
#' prune.out = prune_archetypes(ACTION.out$C, ACTION.out$H)
#'	G = build_ACTIONet(prune.out$H_stacked)
#' unification.out = unify_archetypes(G, S_r, prune.out$C_stacked, prune.out$H_stacked)
#' cell.clusters = unification.out$sample_assignments
#'	S.norm = renormalize_input_matrix(S, cell.clusters)
#'	logPvals.list = compute_archetype_feature_specificity(S.norm, unification.out$H_unified)
#' specificity.scores = logPvals.list$upper_significance
compute_archetype_feature_specificity <- function(S, H) {
    .Call(`_ACTIONet_compute_archetype_feature_specificity`, S, H)
}

#' Compute feature specificity (from cluster assignments)
#'
#' @param S Input matrix
#' @param sample_assignments Vector of cluster assignments
#' 
#' @return A list with the over/under-logPvals
#' 
#' @examples
#' prune.out = prune_archetypes(ACTION.out$C, ACTION.out$H)
#'	G = build_ACTIONet(prune.out$H_stacked)
#' unification.out = unify_archetypes(G, S_r, prune.out$C_stacked, prune.out$H_stacked)
#' cell.clusters = unification.out$sample_assignments
#'	S.norm = renormalize_input_matrix(S, cell.clusters)
#'	logPvals.list = compute_cluster_feature_specificity(S.norm, cell.clusters)
#' specificity.scores = logPvals.list$upper_significance
compute_cluster_feature_specificity <- function(S, sample_assignments) {
    .Call(`_ACTIONet_compute_cluster_feature_specificity`, S, sample_assignments)
}

#' Compute coreness of graph vertices
#'
#' @param G Input graph
#' 
#' @return cn core-number of each graph node
#' 
#' @examples
#' G = colNets(ace)$ACTIONet
#' cn = compute_core_number(G)
compute_core_number <- function(G) {
    .Call(`_ACTIONet_compute_core_number`, G)
}

#' Compute coreness of subgraph vertices induced by each archetype
#'
#' @param G Input graph
#' @param sample_assignments Archetype discretization (output of unify_archetypes())
#' 
#' @return cn core-number of each graph node
#' 
#' @examples
#' G = colNets(ace)$ACTIONet
#' assignments = ace$archetype.assignment
#' connectivity = compute_core_number(G, assignments)
compute_archetype_core_centrality <- function(G, sample_assignments) {
    .Call(`_ACTIONet_compute_archetype_core_centrality`, G, sample_assignments)
}

#' Computes network diffusion over a given network, starting with an arbitrarty set of initial scores
#'
#' @param G Input graph
#' @param X0 Matrix of initial values per diffusion (ncol(G) == nrow(G) == ncol(X0))
#' @param thread_no Number of parallel threads
#' @param alpha Random-walk depth ( between [0, 1] )
#' @param max_it PageRank iterations
#' 
#' @return Matrix of diffusion scores
#' 
#' @examples
#' G = colNets(ace)$ACTIONet
#' gene.expression = Matrix::t(logcounts(ace))[c("CD19", "CD14", "CD16"), ]
#' smoothed.expression = compute_network_diffusion(G, gene.expression)
compute_network_diffusion <- function(G, X0, thread_no = 4L, alpha = 0.85, max_it = 3L) {
    .Call(`_ACTIONet_compute_network_diffusion`, G, X0, thread_no, alpha, max_it)
}

#' Computes sparse network diffusion over a given network, starting with an arbitrarty set of initial scores
#'
#' @param G Input graph
#' @param X0 Matrix of initial values per diffusion (ncol(G) == nrow(G) == ncol(X0))
#' @param alpha Random-walk depth ( between [0, 1] )
#' @param rho Sparsity controling parameter
#' @param epsilon,max_it Conditions on the length of diffusion 
#' 
#' @return Matrix of sparse diffusion scores
#' 
#' @examples
#' G = colNets(ace)$ACTIONet
#' gene.expression = Matrix::t(logcounts(ace))[c("CD19", "CD14", "CD16"), ]
#' smoothed.expression = compute_sparse_network_diffusion(G, gene.expression)
compute_sparse_network_diffusion <- function(G, X0, alpha = 0.85, rho = 1e-4, epsilon = 0.001, max_iter = 20L) {
    .Call(`_ACTIONet_compute_sparse_network_diffusion`, G, X0, alpha, rho, epsilon, max_iter)
}

#' Computes feature enrichment wrt a given annotation
#'
#' @param scores Specificity scores of features
#' @param associations Binary matrix of annotations
#' @param L Length of the top-ranked scores to scan
#' 
#' @return Matrix of log-pvalues
#' 
#' @examples
#' data("gProfilerDB_human")
#' G = colNets(ace)$ACTIONet
#' associations = gProfilerDB_human$SYMBOL$REAC
#' common.genes = intersect(rownames(ace), rownames(associations))
#' specificity_scores = rowFactors(ace)[["archetype_gene_specificity"]]
#' logPvals = compute_feature_specificity(specificity_scores[common.genes, ], annotations[common.genes, ])
#' rownames(logPvals) = colnames(specificity_scores)
#' colnames(logPvals) = colnames(annotations)
assess_enrichment <- function(scores, associations, L) {
    .Call(`_ACTIONet_assess_enrichment`, scores, associations, L)
}

#' Computes disjoint clusters for vertices of G.
#' (It uses an adjusted DBSCAN procedure)
#'
#' @param G Adjacency matrix of the input graph
#' @param minPts, eps DBSCAN parameters
#' @param alpha Diffusion parameter for initial node ordering
#' 
#' @return Matrix of log-pvalues
#' 
#' @examples
#' G = colNets(ace)$ACTIONet
#' clusters = NetDBSCAN(G)
NetDBSCAN <- function(G, minPts = 10L, eps = 0.5, alpha = 0.85) {
    .Call(`_ACTIONet_NetDBSCAN`, G, minPts, eps, alpha)
}

#' Clusters data points using the hierarchical DBSCAN algorithm.
#'
#' @param X Input data matrix with each row being a data point
#' 
#' @return A list with \itemize{
#' \item labels
#' \item membershipProbabilities
#' \item outlierScores
#'}
#' 
#' @examples
#' S_r = t(reducedDims(ace)[["S_r"]])
#' W_r = S_r %*% trace$pruning.out$C_stacked
#' X = Matrix::t(W_r)
#' HDBSCAN.out = run_HDBSCAN(X)
#' clusters = HDBSCAN.out$labels
run_HDBSCAN <- function(X, minPoints = 5L, minClusterSize = 5L) {
    .Call(`_ACTIONet_run_HDBSCAN`, X, minPoints, minClusterSize)
}

